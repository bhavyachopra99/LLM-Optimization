{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data:   0%|          | 1/5000 [00:00<03:42, 22.50it/s]\n",
      "Training epochs:   0%|          | 0/10 [00:00<?, ?it/s]2024-10-13 02:28:20.108454: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:28:41.364190: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  10%|█         | 1/10 [00:21<03:13, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Generator Loss: 20.0593, Discriminator Loss: 0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:28:41.560983: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:28:50.889105: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  20%|██        | 2/10 [00:31<01:55, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Generator Loss: 16.2914, Discriminator Loss: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:28:51.081556: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:00.259656: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  30%|███       | 3/10 [00:40<01:24, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Generator Loss: 15.5151, Discriminator Loss: 0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:00.446831: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:09.650202: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  40%|████      | 4/10 [00:49<01:06, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Generator Loss: 15.4369, Discriminator Loss: 0.8235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:09.844017: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:19.023463: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  50%|█████     | 5/10 [00:59<00:52, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Generator Loss: 15.6265, Discriminator Loss: 0.7555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:19.215420: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:28.308390: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  60%|██████    | 6/10 [01:08<00:40, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Generator Loss: 15.7089, Discriminator Loss: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:28.497820: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:37.566596: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  70%|███████   | 7/10 [01:17<00:29,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Generator Loss: 16.5692, Discriminator Loss: 0.4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:37.756113: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:46.850718: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  80%|████████  | 8/10 [01:26<00:19,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Generator Loss: 16.6566, Discriminator Loss: 0.4419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:47.036472: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:29:56.514569: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  90%|█████████ | 9/10 [01:36<00:09,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Generator Loss: 17.2614, Discriminator Loss: 0.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:29:56.695538: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:30:05.702536: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  90%|█████████ | 9/10 [01:45<00:09,  9.64s/it]2024-10-13 02:30:05.911745: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Generator Loss: 14.3535, Discriminator Loss: 0.9362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs: 100%|██████████| 10/10 [01:46<00:00, 10.62s/it]\n",
      "2024-10-13 02:30:06.303285: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "Calculating metrics: 100%|██████████| 32/32 [00:00<00:00, 225.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM Score: 0.8731\n",
      "PSNR Score: 21.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "def preprocess_image(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def rgb_to_grayscale(image):\n",
    "    return tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "def load_and_preprocess_data(batch_size=32, num_samples=5000):\n",
    "    # Load CIFAR-10 dataset\n",
    "    dataset, info = tfds.load('cifar10', with_info=True, as_supervised=True)\n",
    "    train_dataset = dataset['train'].take(num_samples)\n",
    "    \n",
    "    # Preprocess and batch the data\n",
    "    total_samples = num_samples\n",
    "    with tqdm(total=total_samples, desc=\"Preprocessing data\") as pbar:\n",
    "        def preprocess_and_update(img, label):\n",
    "            pbar.update(1)\n",
    "            return preprocess_image(img), preprocess_image(img)\n",
    "        \n",
    "        train_dataset = train_dataset.map(preprocess_and_update, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(lambda img_color, img_color2: (rgb_to_grayscale(img_color), img_color2), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.batch(batch_size).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset\n",
    "\n",
    "# Update the generator and discriminator to work with 32x32 images\n",
    "def build_generator():\n",
    "    inputs = keras.Input(shape=(32, 32, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    e1 = keras.layers.Conv2D(64, 4, strides=2, padding='same')(inputs)  # 16x16x64\n",
    "    e1 = keras.layers.LeakyReLU(0.2)(e1)\n",
    "    \n",
    "    e2 = keras.layers.Conv2D(128, 4, strides=2, padding='same')(e1)    # 8x8x128\n",
    "    e2 = keras.layers.BatchNormalization()(e2)\n",
    "    e2 = keras.layers.LeakyReLU(0.2)(e2)\n",
    "    \n",
    "    # Bridge\n",
    "    b = keras.layers.Conv2D(256, 4, strides=1, padding='same')(e2)     # 8x8x256\n",
    "    b = keras.layers.BatchNormalization()(b)\n",
    "    b = keras.layers.LeakyReLU(0.2)(b)\n",
    "    \n",
    "    # Decoder\n",
    "    d2 = keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same')(b)  # 16x16x128\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    d2 = keras.layers.Concatenate()([d2, e1])                               # 16x16x192\n",
    "    \n",
    "    # Optionally, add a Conv2D layer to reduce channels\n",
    "    d2 = keras.layers.Conv2D(128, 3, padding='same')(d2)                   # 16x16x128\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    \n",
    "    d1 = keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same')(d2)   # 32x32x64\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    d1 = keras.layers.Concatenate()([d1, inputs])                            # 32x32x65\n",
    "    \n",
    "    # Optionally, add a Conv2D layer to reduce channels\n",
    "    d1 = keras.layers.Conv2D(64, 3, padding='same')(d1)                     # 32x32x64\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(3, 4, strides=1, padding='same', activation='tanh')(d1)  # 32x32x3\n",
    "    \n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = keras.Input(shape=(32, 32, 1))\n",
    "    target_img = keras.Input(shape=(32, 32, 3))\n",
    "    x = keras.layers.Concatenate()([input_img, target_img])\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 4, strides=2, padding='same')(x)  # 16x16x64\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(128, 4, strides=2, padding='same')(x)  # 8x8x128\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(256, 4, strides=2, padding='same')(x)  # 4x4x256\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(1, 4, strides=1, padding='same')(x)    # 4x4x1\n",
    "    \n",
    "    return keras.Model([input_img, target_img], x)\n",
    "\n",
    "# 4. Loss Functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_loss = gan_loss + (100 * l1_loss)\n",
    "    return total_loss, gan_loss, l1_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_loss = real_loss + generated_loss\n",
    "    return total_loss\n",
    "\n",
    "# 5. Training Step\n",
    "@tf.function\n",
    "def train_step(input_image, target, generator, discriminator, generator_optimizer, discriminator_optimizer):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        \n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "        \n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_total_loss, disc_loss\n",
    "\n",
    "# 6. Training Loop is now integrated into main\n",
    "\n",
    "# 7. Image Generation and Saving (Updated)\n",
    "def generate_and_save_images(model, epoch, test_input, max_images=16):\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    num_images = min(predictions.shape[0], max_images)\n",
    "    grid_size = math.ceil(math.sqrt(num_images))\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(grid_size, grid_size, i+1)\n",
    "        img = (predictions[i] * 0.5) + 0.5\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 8. Evaluation Metrics\n",
    "def calculate_metrics(real_images, generated_images, win_size=7):\n",
    "    \"\"\"\n",
    "    Calculate the average SSIM and PSNR between real and generated images.\n",
    "\n",
    "    Args:\n",
    "        real_images (tf.Tensor): Batch of real images.\n",
    "        generated_images (tf.Tensor): Batch of generated images.\n",
    "        win_size (int): Window size for SSIM. Must be odd and <= min(image dimensions).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average SSIM, average PSNR)\n",
    "    \"\"\"\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    \n",
    "    for real, generated in tqdm(zip(real_images, generated_images), desc=\"Calculating metrics\", total=len(real_images)):\n",
    "        # Rescale images from [-1, 1] to [0, 255]\n",
    "        real = ((real * 0.5) + 0.5) * 255\n",
    "        generated = ((generated * 0.5) + 0.5) * 255\n",
    "        \n",
    "        # Convert tensors to NumPy arrays\n",
    "        real = real.numpy().astype(np.uint8)\n",
    "        generated = generated.numpy().astype(np.uint8)\n",
    "        \n",
    "        # Ensure images have 3 channels\n",
    "        if real.ndim == 3 and real.shape[-1] == 1:\n",
    "            real = np.squeeze(real, axis=-1)\n",
    "        if generated.ndim == 3 and generated.shape[-1] == 1:\n",
    "            generated = np.squeeze(generated, axis=-1)\n",
    "        \n",
    "        # Calculate SSIM with updated parameters\n",
    "        ssim_val = ssim(\n",
    "            real, \n",
    "            generated, \n",
    "            win_size=win_size, \n",
    "            channel_axis=-1\n",
    "        )\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_val = psnr(\n",
    "            real, \n",
    "            generated, \n",
    "            data_range=255\n",
    "        )\n",
    "        \n",
    "        ssim_scores.append(ssim_val)\n",
    "        psnr_scores.append(psnr_val)\n",
    "    \n",
    "    return np.mean(ssim_scores), np.mean(psnr_scores)\n",
    "\n",
    "\n",
    "# 9. Main Execution (Updated)\n",
    "def main():\n",
    "    # Create a directory to save CSV and images if not exists\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    \n",
    "    # Initialize CSV file\n",
    "    csv_file = os.path.join('output', 'training_metrics.csv')\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'Generator Loss', 'Discriminator Loss'])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    dataset = load_and_preprocess_data()\n",
    "    \n",
    "    # Build models\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    # Define optimizers\n",
    "    generator_optimizer = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    \n",
    "    # Define number of epochs\n",
    "    epochs = 10\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training epochs\"):\n",
    "        gen_losses = []\n",
    "        disc_losses = []\n",
    "        \n",
    "        for input_image, target in tqdm(dataset, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            gen_total_loss, disc_loss = train_step(input_image, target, generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
    "            gen_losses.append(gen_total_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "        \n",
    "        avg_gen_loss = tf.reduce_mean(gen_losses).numpy()\n",
    "        avg_disc_loss = tf.reduce_mean(disc_losses).numpy()\n",
    "        \n",
    "        tqdm.write(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        tqdm.write(f\"Generator Loss: {avg_gen_loss:.4f}, Discriminator Loss: {avg_disc_loss:.4f}\")\n",
    "        \n",
    "        # Log to CSV\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch+1, avg_gen_loss, avg_disc_loss])\n",
    "        \n",
    "        # Save images every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # Select a batch of test images (you might want to use a fixed set for consistency)\n",
    "            test_dataset = dataset.take(1)\n",
    "            test_grayscale, test_color = next(iter(test_dataset))\n",
    "            generate_and_save_images(generator, epoch + 1, test_grayscale)\n",
    "    \n",
    "    test_dataset = dataset.take(32)\n",
    "    test_grayscale, test_color = next(iter(test_dataset))\n",
    "    generated_images = generator(test_grayscale, training=False)\n",
    "    \n",
    "    ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "    print(f\"SSIM Score: {ssim_score:.4f}\")\n",
    "    print(f\"PSNR Score: {psnr_score:.4f}\")\n",
    "    \n",
    "    # Append evaluation metrics to CSV\n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Evaluation', ssim_score, psnr_score])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data:   0%|          | 1/5000 [00:00<12:19,  6.76it/s]\n",
      "2024-10-13 02:33:48.611872: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "Training epochs:   0%|          | 0/100 [00:00<?, ?it/s]2024-10-13 02:34:02.342452: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:09.487322: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:34:10.437768: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:10.470388: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   0%|          | 0/100 [00:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Generator Loss: 37.3097, Discriminator Loss: 0.7813\n",
      "Validation Generator Loss: 35.6143, Validation Discriminator Loss: 1.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   1%|          | 1/100 [00:22<36:43, 22.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:34:17.319495: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:19.509650: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:34:20.038199: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:20.063811: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   2%|▏         | 2/100 [00:31<24:00, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "Generator Loss: 36.9919, Discriminator Loss: 0.4614\n",
      "Validation Generator Loss: 33.8303, Validation Discriminator Loss: 1.5349\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:34:26.563716: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:28.666810: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:34:29.188695: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:29.219170: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   3%|▎         | 3/100 [00:40<19:39, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "Generator Loss: 37.2943, Discriminator Loss: 0.5080\n",
      "Validation Generator Loss: 34.0764, Validation Discriminator Loss: 1.1682\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:34:35.834570: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:37.981000: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:34:38.520483: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:38.554846: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   4%|▍         | 4/100 [00:50<17:40, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "Generator Loss: 37.1762, Discriminator Loss: 0.5794\n",
      "Validation Generator Loss: 33.6501, Validation Discriminator Loss: 1.5288\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:34:45.258497: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:47.378115: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:34:47.906805: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:47.935615: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   5%|▌         | 5/100 [00:59<16:32, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "Generator Loss: 36.7406, Discriminator Loss: 0.5866\n",
      "Validation Generator Loss: 33.0085, Validation Discriminator Loss: 1.4930\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:34:54.578962: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:56.821904: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:34:57.356317: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:34:57.391236: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   6%|▌         | 6/100 [01:08<15:44, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "Generator Loss: 36.5761, Discriminator Loss: 0.6553\n",
      "Validation Generator Loss: 33.8889, Validation Discriminator Loss: 1.7836\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:03.769410: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:05.895851: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:35:06.421357: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:06.452107: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   7%|▋         | 7/100 [01:17<15:04,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "Generator Loss: 36.2320, Discriminator Loss: 0.6596\n",
      "Validation Generator Loss: 34.2767, Validation Discriminator Loss: 1.4527\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:12.934073: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:15.020425: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:35:15.584233: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:15.619754: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   8%|▊         | 8/100 [01:27<14:38,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "Generator Loss: 36.2172, Discriminator Loss: 0.6716\n",
      "Validation Generator Loss: 35.1196, Validation Discriminator Loss: 1.4186\n",
      "No improvement in validation loss for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:22.061284: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:24.179623: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:35:24.722281: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:24.754715: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   9%|▉         | 9/100 [01:36<14:17,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "Generator Loss: 36.0752, Discriminator Loss: 0.6671\n",
      "Validation Generator Loss: 34.4054, Validation Discriminator Loss: 1.4907\n",
      "No improvement in validation loss for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:31.471746: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:33.626639: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:35:34.158160: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:34.188627: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   9%|▉         | 9/100 [01:45<14:17,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "Generator Loss: 35.9284, Discriminator Loss: 0.6859\n",
      "Validation Generator Loss: 33.2915, Validation Discriminator Loss: 1.2158\n",
      "No improvement in validation loss for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics: 100%|██████████| 32/32 [00:00<00:00, 223.59it/s]\n",
      "Training epochs:  10%|█         | 10/100 [01:46<14:27,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM Score: 0.4748\n",
      "PSNR Score: 15.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:41.328905: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:43.480124: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:35:44.003116: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:44.031762: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  11%|█         | 11/100 [01:55<14:09,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "Generator Loss: 35.8700, Discriminator Loss: 0.6470\n",
      "Validation Generator Loss: 32.9931, Validation Discriminator Loss: 1.2532\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:50.672058: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:52.795698: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:35:53.336674: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:35:53.366680: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  12%|█▏        | 12/100 [02:04<13:49,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "Generator Loss: 35.5830, Discriminator Loss: 0.6573\n",
      "Validation Generator Loss: 34.3305, Validation Discriminator Loss: 1.2967\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:35:59.884994: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:02.061778: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:02.595520: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:02.627544: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  13%|█▎        | 13/100 [02:14<13:35,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "Generator Loss: 35.4862, Discriminator Loss: 0.6583\n",
      "Validation Generator Loss: 36.2427, Validation Discriminator Loss: 1.2783\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:36:08.926047: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:11.001780: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:11.517785: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:11.548392: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  14%|█▍        | 14/100 [02:22<13:14,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "Generator Loss: 35.3503, Discriminator Loss: 0.6378\n",
      "Validation Generator Loss: 37.4768, Validation Discriminator Loss: 1.2825\n",
      "No improvement in validation loss for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:36:17.953501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:20.021158: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:20.546441: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:20.575606: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  15%|█▌        | 15/100 [02:31<12:59,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "Generator Loss: 35.2367, Discriminator Loss: 0.5816\n",
      "Validation Generator Loss: 35.0972, Validation Discriminator Loss: 1.3394\n",
      "No improvement in validation loss for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:36:27.088920: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:29.253231: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:29.806263: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:29.836383: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  16%|█▌        | 16/100 [02:41<12:52,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "Generator Loss: 35.2611, Discriminator Loss: 0.5917\n",
      "Validation Generator Loss: 33.9597, Validation Discriminator Loss: 1.2762\n",
      "No improvement in validation loss for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:36:36.563354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:38.687977: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:39.217938: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:39.245522: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  17%|█▋        | 17/100 [02:50<12:53,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "Generator Loss: 35.1133, Discriminator Loss: 0.6330\n",
      "Validation Generator Loss: 32.9222, Validation Discriminator Loss: 1.2236\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:36:45.816797: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:47.936071: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:48.497438: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:48.530554: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  18%|█▊        | 18/100 [02:59<12:38,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "Generator Loss: 34.9588, Discriminator Loss: 0.6056\n",
      "Validation Generator Loss: 34.0757, Validation Discriminator Loss: 1.6225\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:36:55.025306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:57.170563: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:36:57.696668: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:36:57.729231: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  19%|█▉        | 19/100 [03:09<12:28,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "Generator Loss: 34.7161, Discriminator Loss: 0.6275\n",
      "Validation Generator Loss: 33.2473, Validation Discriminator Loss: 1.4901\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:04.502510: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:06.653309: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:37:07.191817: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:07.223136: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  19%|█▉        | 19/100 [03:18<12:28,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "Generator Loss: 34.4345, Discriminator Loss: 0.6121\n",
      "Validation Generator Loss: 33.7939, Validation Discriminator Loss: 1.6383\n",
      "No improvement in validation loss for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics: 100%|██████████| 32/32 [00:00<00:00, 442.15it/s]\n",
      "Training epochs:  20%|██        | 20/100 [03:18<12:32,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM Score: 0.6030\n",
      "PSNR Score: 15.7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:13.790313: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:15.819796: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:37:16.335366: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:16.361978: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  21%|██        | 21/100 [03:27<12:09,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "Generator Loss: 34.4313, Discriminator Loss: 0.6328\n",
      "Validation Generator Loss: 32.7748, Validation Discriminator Loss: 1.4212\n",
      "No improvement in validation loss for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:22.626227: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:24.673825: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:37:25.176804: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:25.208309: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  22%|██▏       | 22/100 [03:36<11:51,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "Generator Loss: 34.2099, Discriminator Loss: 0.6012\n",
      "Validation Generator Loss: 34.0707, Validation Discriminator Loss: 1.3580\n",
      "No improvement in validation loss for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:31.577457: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:33.612320: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:37:34.125406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:34.152009: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  23%|██▎       | 23/100 [03:45<11:38,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "Generator Loss: 34.1278, Discriminator Loss: 0.6062\n",
      "Validation Generator Loss: 40.5748, Validation Discriminator Loss: 1.4003\n",
      "No improvement in validation loss for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:40.649504: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:42.693080: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:37:43.209956: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:43.237711: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  24%|██▍       | 24/100 [03:54<11:29,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "Generator Loss: 34.1880, Discriminator Loss: 0.6281\n",
      "Validation Generator Loss: 34.2168, Validation Discriminator Loss: 1.6371\n",
      "No improvement in validation loss for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:49.424176: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:51.447302: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:37:51.960356: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:37:51.990815: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  25%|██▌       | 25/100 [04:03<11:13,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "Generator Loss: 33.8618, Discriminator Loss: 0.6154\n",
      "Validation Generator Loss: 34.5666, Validation Discriminator Loss: 1.4141\n",
      "No improvement in validation loss for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:37:58.254352: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:38:00.285513: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:38:00.787531: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:38:00.816193: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  26%|██▌       | 26/100 [04:12<11:00,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "Generator Loss: 33.6681, Discriminator Loss: 0.5969\n",
      "Validation Generator Loss: 36.2486, Validation Discriminator Loss: 1.6512\n",
      "No improvement in validation loss for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 02:38:07.243470: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:38:09.349835: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 02:38:09.858698: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 02:38:09.885822: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:  26%|██▌       | 26/100 [04:21<12:23, 10.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "Generator Loss: 33.7762, Discriminator Loss: 0.5732\n",
      "Validation Generator Loss: 38.4997, Validation Discriminator Loss: 1.3148\n",
      "No improvement in validation loss for 10 epochs.\n",
      "Early stopping triggered.\n",
      "Restored from checkpoint: ./checkpoints/ckpt-7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics: 100%|██████████| 32/32 [00:00<00:00, 445.90it/s]\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SSIM Score: 0.4191\n",
      "Final PSNR Score: 14.8780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Enable mixed precision if desired (optional)\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Scales image to [-1, 1].\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def rgb_to_grayscale(image):\n",
    "    \"\"\"Converts RGB image to grayscale.\"\"\"\n",
    "    return tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "def augment(image, label):\n",
    "    \"\"\"Applies random augmentations to images.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label\n",
    "\n",
    "def load_and_preprocess_data(batch_size=32, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 dataset, applies preprocessing and augmentation,\n",
    "    and prepares training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    # Load CIFAR-10 dataset\n",
    "    dataset, info = tfds.load('cifar10', with_info=True, as_supervised=True)\n",
    "    train_dataset = dataset['train'].take(num_samples)\n",
    "\n",
    "    # Define split sizes\n",
    "    val_size = int(0.1 * num_samples)  # 10% for validation\n",
    "    test_size = 32  # Fixed test set size\n",
    "\n",
    "    # Preprocess and augment the data\n",
    "    with tqdm(total=num_samples, desc=\"Preprocessing data\") as pbar:\n",
    "        def preprocess_and_update(img, label):\n",
    "            pbar.update(1)\n",
    "            img = preprocess_image(img)\n",
    "            return img, img  # Input and target are initially the same\n",
    "\n",
    "        train_dataset = train_dataset.map(preprocess_and_update, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(lambda img_color, img_color2: (rgb_to_grayscale(img_color), img_color2),\n",
    "                                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.shuffle(1000)\n",
    "        train_dataset = train_dataset.batch(batch_size)\n",
    "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Split into training and validation\n",
    "    val_dataset = train_dataset.take(val_size // batch_size)\n",
    "    train_dataset = train_dataset.skip(val_size // batch_size)\n",
    "\n",
    "    # Create a fixed test set\n",
    "    test_dataset = dataset['test'].take(test_size).map(lambda img, lbl: preprocess_image(img))\n",
    "    test_dataset = test_dataset.map(lambda img: (rgb_to_grayscale(img), img))\n",
    "    test_dataset = test_dataset.batch(test_size)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# 2. Build Generator\n",
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Builds the generator model with an encoder-decoder architecture\n",
    "    and skip connections.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(32, 32, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    e1 = keras.layers.Conv2D(64, 4, strides=2, padding='same')(inputs)  # 16x16x64\n",
    "    e1 = keras.layers.LeakyReLU(0.2)(e1)\n",
    "    \n",
    "    e2 = keras.layers.Conv2D(128, 4, strides=2, padding='same')(e1)    # 8x8x128\n",
    "    e2 = keras.layers.BatchNormalization()(e2)\n",
    "    e2 = keras.layers.LeakyReLU(0.2)(e2)\n",
    "    \n",
    "    # Bridge\n",
    "    b = keras.layers.Conv2D(256, 4, strides=1, padding='same')(e2)     # 8x8x256\n",
    "    b = keras.layers.BatchNormalization()(b)\n",
    "    b = keras.layers.LeakyReLU(0.2)(b)\n",
    "    \n",
    "    # Decoder\n",
    "    d2 = keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same')(b)  # 16x16x128\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    d2 = keras.layers.Concatenate()([d2, e1])                               # 16x16x192\n",
    "    \n",
    "    # Reduce channels\n",
    "    d2 = keras.layers.Conv2D(128, 3, padding='same')(d2)                   # 16x16x128\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    \n",
    "    d1 = keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same')(d2)   # 32x32x64\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    d1 = keras.layers.Concatenate()([d1, inputs])                            # 32x32x65\n",
    "    \n",
    "    # Reduce channels\n",
    "    d1 = keras.layers.Conv2D(64, 3, padding='same')(d1)                     # 32x32x64\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(3, 4, strides=1, padding='same', activation='tanh')(d1)  # 32x32x3\n",
    "    \n",
    "    return keras.Model(inputs, outputs, name=\"Generator\")\n",
    "\n",
    "# 3. Build Discriminator\n",
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Builds the discriminator model to classify real and generated images.\n",
    "    \"\"\"\n",
    "    input_img = keras.Input(shape=(32, 32, 1))\n",
    "    target_img = keras.Input(shape=(32, 32, 3))\n",
    "    x = keras.layers.Concatenate()([input_img, target_img])  # 32x32x4\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 4, strides=2, padding='same')(x)  # 16x16x64\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(128, 4, strides=2, padding='same')(x)  # 8x8x128\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(256, 4, strides=2, padding='same')(x)  # 4x4x256\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(1, 4, strides=1, padding='same')(x)    # 4x4x1\n",
    "    \n",
    "    return keras.Model([input_img, target_img], x, name=\"Discriminator\")\n",
    "\n",
    "# 4. Loss Functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    \"\"\"\n",
    "    Calculates generator loss which is a combination of GAN loss and L1 loss.\n",
    "    \"\"\"\n",
    "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_loss = gan_loss + (100 * l1_loss)\n",
    "    return total_loss, gan_loss, l1_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    \"\"\"\n",
    "    Calculates discriminator loss.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_loss = real_loss + generated_loss\n",
    "    return total_loss\n",
    "\n",
    "# 5. Training Step\n",
    "@tf.function\n",
    "def train_step(input_image, target, generator, discriminator, generator_optimizer, discriminator_optimizer):\n",
    "    \"\"\"\n",
    "    Performs one training step for both generator and discriminator.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate output\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        \n",
    "        # Discriminator output\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "        \n",
    "        # Calculate losses\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_total_loss, disc_loss\n",
    "\n",
    "# 6. Image Generation and Saving\n",
    "def generate_and_save_images(model, epoch, test_input, save_dir='output', max_images=16):\n",
    "    \"\"\"\n",
    "    Generates images using the generator and saves them to disk.\n",
    "    \"\"\"\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    num_images = min(predictions.shape[0], max_images)\n",
    "    grid_size = math.ceil(math.sqrt(num_images))\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(grid_size, grid_size, i+1)\n",
    "        img = (predictions[i] * 0.5) + 0.5  # Rescale to [0, 1]\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 7. Evaluation Metrics\n",
    "def calculate_metrics(real_images, generated_images, win_size=7):\n",
    "    \"\"\"\n",
    "    Calculates average SSIM and PSNR between real and generated images.\n",
    "    \n",
    "    Args:\n",
    "        real_images (tf.Tensor): Batch of real images.\n",
    "        generated_images (tf.Tensor): Batch of generated images.\n",
    "        win_size (int): Window size for SSIM. Must be odd and <= min(image dimensions).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average SSIM, average PSNR)\n",
    "    \"\"\"\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    \n",
    "    for real, generated in tqdm(zip(real_images, generated_images), desc=\"Calculating metrics\", total=len(real_images)):\n",
    "        # Rescale images from [-1, 1] to [0, 255]\n",
    "        real = ((real * 0.5) + 0.5) * 255\n",
    "        generated = ((generated * 0.5) + 0.5) * 255\n",
    "        \n",
    "        # Convert tensors to NumPy arrays\n",
    "        real = real.numpy().astype(np.uint8)\n",
    "        generated = generated.numpy().astype(np.uint8)\n",
    "        \n",
    "        # Ensure images have 3 channels\n",
    "        if real.ndim == 3 and real.shape[-1] == 1:\n",
    "            real = np.squeeze(real, axis=-1)\n",
    "        if generated.ndim ==3 and generated.shape[-1] ==1:\n",
    "            generated = np.squeeze(generated, axis=-1)\n",
    "        \n",
    "        # Calculate SSIM with updated parameters\n",
    "        try:\n",
    "            ssim_val = ssim(\n",
    "                real, \n",
    "                generated, \n",
    "                win_size=win_size, \n",
    "                channel_axis=-1\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"SSIM calculation error: {e}\")\n",
    "            ssim_val = 0  # Assign a default value or handle as needed\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_val = psnr(\n",
    "            real, \n",
    "            generated, \n",
    "            data_range=255\n",
    "        )\n",
    "        \n",
    "        ssim_scores.append(ssim_val)\n",
    "        psnr_scores.append(psnr_val)\n",
    "    \n",
    "    return np.mean(ssim_scores), np.mean(psnr_scores)\n",
    "\n",
    "# 8. Main Execution with Enhancements\n",
    "def main():\n",
    "    # Set random seed for reproducibility (optional)\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create a directory to save outputs if not exists\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    \n",
    "    # Initialize CSV files\n",
    "    train_csv_file = os.path.join('output', 'training_metrics.csv')\n",
    "    eval_csv_file = os.path.join('output', 'evaluation_metrics.csv')\n",
    "    \n",
    "    with open(train_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'Generator Loss', 'Discriminator Loss'])\n",
    "    \n",
    "    with open(eval_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'SSIM Score', 'PSNR Score'])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    train_dataset, val_dataset, test_dataset = load_and_preprocess_data()\n",
    "    \n",
    "    # Build models\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    # Define optimizers\n",
    "    generator_optimizer = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    \n",
    "    # Define number of epochs\n",
    "    epochs = 100\n",
    "    patience = 10  # For early stopping\n",
    "    \n",
    "    # Setup TensorBoard\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Setup Model Checkpointing\n",
    "    checkpoint_dir = './checkpoints'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        generator_optimizer=generator_optimizer,\n",
    "        discriminator_optimizer=discriminator_optimizer\n",
    "    )\n",
    "    \n",
    "    # Select a fixed test set for consistent evaluation\n",
    "    test_grayscale, test_color = next(iter(test_dataset))\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in tqdm(range(1, epochs + 1), desc=\"Training epochs\"):\n",
    "        gen_losses = []\n",
    "        disc_losses = []\n",
    "        \n",
    "        # Training\n",
    "        for input_image, target in tqdm(train_dataset, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "            gen_total_loss, disc_loss = train_step(input_image, target, generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
    "            gen_losses.append(gen_total_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_gen_loss = tf.reduce_mean(gen_losses).numpy()\n",
    "        avg_disc_loss = tf.reduce_mean(disc_losses).numpy()\n",
    "        \n",
    "        # Validation\n",
    "        val_gen_losses = []\n",
    "        val_disc_losses = []\n",
    "        for val_input, val_target in val_dataset:\n",
    "            # Generate output\n",
    "            gen_output = generator(val_input, training=False)\n",
    "            \n",
    "            # Discriminator output\n",
    "            disc_real_output = discriminator([val_input, val_target], training=False)\n",
    "            disc_generated_output = discriminator([val_input, gen_output], training=False)\n",
    "            \n",
    "            # Calculate losses\n",
    "            val_gen_total_loss, val_gen_gan_loss, val_gen_l1_loss = generator_loss(disc_generated_output, gen_output, val_target)\n",
    "            val_disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            val_gen_losses.append(val_gen_total_loss)\n",
    "            val_disc_losses.append(val_disc_loss)\n",
    "        \n",
    "        # Calculate average validation losses\n",
    "        avg_val_gen_loss = tf.reduce_mean(val_gen_losses).numpy()\n",
    "        avg_val_disc_loss = tf.reduce_mean(val_disc_losses).numpy()\n",
    "        avg_val_loss = avg_val_gen_loss + avg_val_disc_loss\n",
    "        \n",
    "        # Log training losses to CSV\n",
    "        with open(train_csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch, avg_gen_loss, avg_disc_loss])\n",
    "        \n",
    "        # Log validation losses to TensorBoard\n",
    "        with tf.summary.create_file_writer(log_dir).as_default():\n",
    "            tf.summary.scalar('Generator Loss (Train)', avg_gen_loss, step=epoch)\n",
    "            tf.summary.scalar('Discriminator Loss (Train)', avg_disc_loss, step=epoch)\n",
    "            tf.summary.scalar('Generator Loss (Val)', avg_val_gen_loss, step=epoch)\n",
    "            tf.summary.scalar('Discriminator Loss (Val)', avg_val_disc_loss, step=epoch)\n",
    "            tf.summary.scalar('Total Validation Loss', avg_val_loss, step=epoch)\n",
    "        \n",
    "        # Print metrics\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}\")\n",
    "        tqdm.write(f\"Generator Loss: {avg_gen_loss:.4f}, Discriminator Loss: {avg_disc_loss:.4f}\")\n",
    "        tqdm.write(f\"Validation Generator Loss: {avg_val_gen_loss:.4f}, Validation Discriminator Loss: {avg_val_disc_loss:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            wait = 0\n",
    "            # Save the best models\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            tqdm.write(\"Validation loss improved. Checkpoint saved.\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            tqdm.write(f\"No improvement in validation loss for {wait} epochs.\")\n",
    "            if wait >= patience:\n",
    "                tqdm.write(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Every 10 epochs, perform evaluation\n",
    "        if epoch % 10 == 0:\n",
    "            # Generate images\n",
    "            generate_and_save_images(generator, epoch, test_grayscale)\n",
    "            \n",
    "            # Generate output\n",
    "            generated_images = generator(test_grayscale, training=False)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "            tqdm.write(f\"SSIM Score: {ssim_score:.4f}\")\n",
    "            tqdm.write(f\"PSNR Score: {psnr_score:.4f}\")\n",
    "            \n",
    "            # Log evaluation metrics to separate CSV\n",
    "            with open(eval_csv_file, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([epoch, ssim_score, psnr_score])\n",
    "            \n",
    "            # Log evaluation metrics to TensorBoard\n",
    "            with tf.summary.create_file_writer(log_dir).as_default():\n",
    "                tf.summary.scalar('SSIM Score', ssim_score, step=epoch)\n",
    "                tf.summary.scalar('PSNR Score', psnr_score, step=epoch)\n",
    "    \n",
    "    # After training, perform final evaluation\n",
    "    # Optionally, load the best checkpoint\n",
    "    latest_ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if latest_ckpt:\n",
    "        checkpoint.restore(latest_ckpt)\n",
    "        tqdm.write(f\"Restored from checkpoint: {latest_ckpt}\")\n",
    "    \n",
    "    # Final evaluation on the fixed test set\n",
    "    generated_images = generator(test_grayscale, training=False)\n",
    "    ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "    print(f\"Final SSIM Score: {ssim_score:.4f}\")\n",
    "    print(f\"Final PSNR Score: {psnr_score:.4f}\")\n",
    "    \n",
    "    # Append final evaluation metrics to CSV\n",
    "    with open(eval_csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Final Evaluation', ssim_score, psnr_score])\n",
    "    \n",
    "    # Optionally, save the final models\n",
    "    generator.save('output/final_generator.h5')\n",
    "    discriminator.save('output/final_discriminator.h5')\n",
    "    print(\"Models saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data:   0%|          | 1/5000 [00:00<09:11,  9.07it/s]\n",
      "2024-10-13 09:26:00.456888: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "Training epochs:   0%|          | 0/100 [00:00<?, ?it/s]2024-10-13 09:26:14.676003: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 09:26:22.892781: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 09:26:23.741440: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 09:26:23.772111: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   0%|          | 0/100 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Generator Loss: 4.6054, Discriminator Loss: 1.2104\n",
      "Validation Generator Loss: 4.2390, Validation Discriminator Loss: 1.3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   1%|          | 1/100 [00:23<38:49, 23.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 09:26:30.621640: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 09:26:32.852796: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-13 09:26:33.380295: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 09:26:33.409163: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Training epochs:   2%|▏         | 2/100 [00:33<25:03, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "Generator Loss: 4.7043, Discriminator Loss: 1.1639\n",
      "Validation Generator Loss: 4.0784, Validation Discriminator Loss: 1.3760\n",
      "Validation loss improved. Checkpoint saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 09:26:40.327583: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "Training epochs:   2%|▏         | 2/100 [00:40<32:45, 20.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 581\u001b[0m\n\u001b[1;32m    578\u001b[0m     plot_metrics(train_csv, eval_csv, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 581\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# After training completes, plot the metrics\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     plot_metrics(\n\u001b[1;32m    584\u001b[0m         train_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/training_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    585\u001b[0m         eval_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/evaluation_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    586\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    587\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[21], line 389\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_image, target \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataset, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 389\u001b[0m     gen_total_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjusted L1 weight\u001b[39;49;00m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     gen_losses\u001b[38;5;241m.\u001b[39mappend(gen_total_loss)\n\u001b[1;32m    395\u001b[0m     disc_losses\u001b[38;5;241m.\u001b[39mappend(disc_loss)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Scales image to [-1, 1].\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def rgb_to_grayscale(image):\n",
    "    \"\"\"Converts RGB image to grayscale.\"\"\"\n",
    "    return tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "def augment(image, label):\n",
    "    \"\"\"Applies random augmentations to images.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label\n",
    "\n",
    "def load_and_preprocess_data(batch_size=32, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 dataset, applies preprocessing and augmentation,\n",
    "    and prepares training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    # Load CIFAR-10 dataset\n",
    "    dataset, info = tfds.load('cifar10', with_info=True, as_supervised=True)\n",
    "    train_dataset = dataset['train'].take(num_samples)\n",
    "\n",
    "    # Define split sizes\n",
    "    val_size = int(0.1 * num_samples)  # 10% for validation\n",
    "    test_size = 32  # Fixed test set size\n",
    "\n",
    "    # Preprocess and augment the data\n",
    "    with tqdm(total=num_samples, desc=\"Preprocessing data\") as pbar:\n",
    "        def preprocess_and_update(img, label):\n",
    "            pbar.update(1)\n",
    "            img = preprocess_image(img)\n",
    "            return img, img  # Input and target are initially the same\n",
    "\n",
    "        train_dataset = train_dataset.map(preprocess_and_update, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(lambda img_color, img_color2: (rgb_to_grayscale(img_color), img_color2),\n",
    "                                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.shuffle(1000)\n",
    "        train_dataset = train_dataset.batch(batch_size)\n",
    "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Split into training and validation\n",
    "    val_dataset = train_dataset.take(val_size // batch_size)\n",
    "    train_dataset = train_dataset.skip(val_size // batch_size)\n",
    "\n",
    "    # Create a fixed test set\n",
    "    test_dataset = dataset['test'].take(test_size).map(lambda img, lbl: preprocess_image(img))\n",
    "    test_dataset = test_dataset.map(lambda img: (rgb_to_grayscale(img), img))\n",
    "    test_dataset = test_dataset.batch(test_size)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Update the generator and discriminator to work with 32x32 images\n",
    "def build_generator():\n",
    "    inputs = keras.Input(shape=(32, 32, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    e1 = keras.layers.Conv2D(64, 4, strides=2, padding='same')(inputs)  # 16x16x64\n",
    "    e1 = keras.layers.LeakyReLU(0.2)(e1)\n",
    "    \n",
    "    e2 = keras.layers.Conv2D(128, 4, strides=2, padding='same')(e1)    # 8x8x128\n",
    "    e2 = keras.layers.BatchNormalization()(e2)\n",
    "    e2 = keras.layers.LeakyReLU(0.2)(e2)\n",
    "    \n",
    "    # Bridge\n",
    "    b = keras.layers.Conv2D(256, 4, strides=1, padding='same')(e2)     # 8x8x256\n",
    "    b = keras.layers.BatchNormalization()(b)\n",
    "    b = keras.layers.LeakyReLU(0.2)(b)\n",
    "    \n",
    "    # Decoder\n",
    "    d2 = keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same')(b)  # 16x16x128\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    d2 = keras.layers.Concatenate()([d2, e1])                               # 16x16x192\n",
    "    \n",
    "    # Optionally, add a Conv2D layer to reduce channels\n",
    "    d2 = keras.layers.Conv2D(128, 3, padding='same')(d2)                   # 16x16x128\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    \n",
    "    d1 = keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same')(d2)   # 32x32x64\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    d1 = keras.layers.Concatenate()([d1, inputs])                            # 32x32x65\n",
    "    \n",
    "    # Optionally, add a Conv2D layer to reduce channels\n",
    "    d1 = keras.layers.Conv2D(64, 3, padding='same')(d1)                     # 32x32x64\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(3, 4, strides=1, padding='same', activation='tanh')(d1)  # 32x32x3\n",
    "    \n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = keras.Input(shape=(32, 32, 1))\n",
    "    target_img = keras.Input(shape=(32, 32, 3))\n",
    "    x = keras.layers.Concatenate()([input_img, target_img])\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 4, strides=2, padding='same')(x)  # 16x16x64\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(128, 4, strides=2, padding='same')(x)  # 8x8x128\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(256, 4, strides=2, padding='same')(x)  # 4x4x256\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(1, 4, strides=1, padding='same')(x)    # 4x4x1\n",
    "    \n",
    "    return keras.Model([input_img, target_img], x)\n",
    "# 4. Loss Functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target, l1_weight=10):\n",
    "    \"\"\"\n",
    "    Calculates generator loss which is a combination of GAN loss and L1 loss.\n",
    "    \"\"\"\n",
    "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_loss = gan_loss + (l1_weight * l1_loss)\n",
    "    return total_loss, gan_loss, l1_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    \"\"\"\n",
    "    Calculates discriminator loss.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_loss = real_loss + generated_loss\n",
    "    return total_loss\n",
    "\n",
    "# 5. Training Step\n",
    "@tf.function\n",
    "def train_step(input_image, target, generator, discriminator, generator_optimizer, discriminator_optimizer, l1_weight=10):\n",
    "    \"\"\"\n",
    "    Performs one training step for both generator and discriminator.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate output\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        \n",
    "        # Discriminator output\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "        \n",
    "        # Calculate losses\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
    "            disc_generated_output, gen_output, target, l1_weight=l1_weight\n",
    "        )\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_total_loss, disc_loss\n",
    "\n",
    "# 6. Image Generation and Saving\n",
    "def generate_and_save_images(model, epoch, test_input, save_dir='output', max_images=16):\n",
    "    \"\"\"\n",
    "    Generates images using the generator and saves them to disk.\n",
    "    \"\"\"\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    num_images = min(predictions.shape[0], max_images)\n",
    "    grid_size = math.ceil(math.sqrt(num_images))\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(grid_size, grid_size, i+1)\n",
    "        img = (predictions[i] * 0.5) + 0.5  # Rescale to [0, 1]\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 7. Evaluation Metrics\n",
    "def calculate_metrics(real_images, generated_images, win_size=7):\n",
    "    \"\"\"\n",
    "    Calculates average SSIM and PSNR between real and generated images.\n",
    "    \n",
    "    Args:\n",
    "        real_images (tf.Tensor): Batch of real images.\n",
    "        generated_images (tf.Tensor): Batch of generated images.\n",
    "        win_size (int): Window size for SSIM. Must be odd and <= min(image dimensions).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average SSIM, average PSNR)\n",
    "    \"\"\"\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    \n",
    "    for real, generated in tqdm(zip(real_images, generated_images), desc=\"Calculating metrics\", total=len(real_images)):\n",
    "        # Rescale images from [-1, 1] to [0, 255]\n",
    "        real = ((real * 0.5) + 0.5) * 255\n",
    "        generated = ((generated * 0.5) + 0.5) * 255\n",
    "        \n",
    "        # Convert tensors to NumPy arrays\n",
    "        real = real.numpy().astype(np.uint8)\n",
    "        generated = generated.numpy().astype(np.uint8)\n",
    "        \n",
    "        # Ensure images have 3 channels\n",
    "        if real.ndim == 3 and real.shape[-1] == 1:\n",
    "            real = np.squeeze(real, axis=-1)\n",
    "        if generated.ndim ==3 and generated.shape[-1] ==1:\n",
    "            generated = np.squeeze(generated, axis=-1)\n",
    "        \n",
    "        # Calculate SSIM with updated parameters\n",
    "        try:\n",
    "            ssim_val = ssim(\n",
    "                real, \n",
    "                generated, \n",
    "                win_size=win_size, \n",
    "                channel_axis=-1\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"SSIM calculation error: {e}\")\n",
    "            ssim_val = 0  # Assign a default value or handle as needed\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_val = psnr(\n",
    "            real, \n",
    "            generated, \n",
    "            data_range=255\n",
    "        )\n",
    "        \n",
    "        ssim_scores.append(ssim_val)\n",
    "        psnr_scores.append(psnr_val)\n",
    "    \n",
    "    return np.mean(ssim_scores), np.mean(psnr_scores)\n",
    "\n",
    "# 8. Plotting Function\n",
    "def plot_metrics(train_csv, eval_csv, output_dir='output'):\n",
    "    \"\"\"\n",
    "    Plots training and evaluation metrics from CSV files.\n",
    "    \n",
    "    Args:\n",
    "        train_csv (str): Path to the training metrics CSV file.\n",
    "        eval_csv (str): Path to the evaluation metrics CSV file.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load training metrics\n",
    "    train_epochs = []\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    with open(train_csv, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            train_epochs.append(int(row['Epoch']))\n",
    "            gen_losses.append(float(row['Generator Loss']))\n",
    "            disc_losses.append(float(row['Discriminator Loss']))\n",
    "    \n",
    "    # Load evaluation metrics\n",
    "    eval_epochs = []\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    with open(eval_csv, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            eval_epochs.append(int(row['Epoch']))\n",
    "            ssim_scores.append(float(row['SSIM Score']))\n",
    "            psnr_scores.append(float(row['PSNR Score']))\n",
    "    \n",
    "    # Plot Generator and Discriminator Losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_epochs, gen_losses, label='Generator Loss')\n",
    "    plt.plot(train_epochs, disc_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'training_losses.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot SSIM and PSNR Scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_epochs, ssim_scores, label='SSIM Score')\n",
    "    plt.plot(eval_epochs, psnr_scores, label='PSNR Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'evaluation_metrics.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Plots saved in '{output_dir}' directory.\")\n",
    "\n",
    "# 9. Main Execution with Enhancements\n",
    "def main():\n",
    "    # Set random seed for reproducibility (optional)\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create a directory to save outputs if not exists\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    \n",
    "    # Initialize CSV files\n",
    "    train_csv_file = os.path.join('output', 'training_metrics.csv')\n",
    "    eval_csv_file = os.path.join('output', 'evaluation_metrics.csv')\n",
    "    \n",
    "    with open(train_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'Generator Loss', 'Discriminator Loss'])\n",
    "    \n",
    "    with open(eval_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'SSIM Score', 'PSNR Score'])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    train_dataset, val_dataset, test_dataset = load_and_preprocess_data()\n",
    "    \n",
    "    # Build models\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    # Define optimizers\n",
    "    generator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)  # Reduced learning rate\n",
    "    discriminator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)  # Reduced learning rate\n",
    "    \n",
    "    # Define number of epochs\n",
    "    epochs = 100\n",
    "    patience = 15  # For early stopping\n",
    "    \n",
    "    # Setup TensorBoard\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Setup Model Checkpointing\n",
    "    checkpoint_dir = './checkpoints'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        generator_optimizer=generator_optimizer,\n",
    "        discriminator_optimizer=discriminator_optimizer\n",
    "    )\n",
    "    \n",
    "    # Select a fixed test set for consistent evaluation\n",
    "    test_grayscale, test_color = next(iter(test_dataset))\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in tqdm(range(1, epochs + 1), desc=\"Training epochs\"):\n",
    "        gen_losses = []\n",
    "        disc_losses = []\n",
    "        \n",
    "        # Training\n",
    "        for input_image, target in tqdm(train_dataset, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "            gen_total_loss, disc_loss = train_step(\n",
    "                input_image, target, generator, discriminator, \n",
    "                generator_optimizer, discriminator_optimizer, \n",
    "                l1_weight=10  # Adjusted L1 weight\n",
    "            )\n",
    "            gen_losses.append(gen_total_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_gen_loss = tf.reduce_mean(gen_losses).numpy()\n",
    "        avg_disc_loss = tf.reduce_mean(disc_losses).numpy()\n",
    "        \n",
    "        # Validation\n",
    "        val_gen_losses = []\n",
    "        val_disc_losses = []\n",
    "        for val_input, val_target in val_dataset:\n",
    "            # Generate output\n",
    "            gen_output = generator(val_input, training=False)\n",
    "            \n",
    "            # Discriminator output\n",
    "            disc_real_output = discriminator([val_input, val_target], training=False)\n",
    "            disc_generated_output = discriminator([val_input, gen_output], training=False)\n",
    "            \n",
    "            # Calculate losses\n",
    "            val_gen_total_loss, val_gen_gan_loss, val_gen_l1_loss = generator_loss(\n",
    "                disc_generated_output, gen_output, val_target, l1_weight=10\n",
    "            )\n",
    "            val_disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            val_gen_losses.append(val_gen_total_loss)\n",
    "            val_disc_losses.append(val_disc_loss)\n",
    "        \n",
    "        # Calculate average validation losses\n",
    "        avg_val_gen_loss = tf.reduce_mean(val_gen_losses).numpy()\n",
    "        avg_val_disc_loss = tf.reduce_mean(val_disc_losses).numpy()\n",
    "        avg_val_loss = avg_val_gen_loss + avg_val_disc_loss\n",
    "        \n",
    "        # Log training losses to CSV\n",
    "        with open(train_csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch, avg_gen_loss, avg_disc_loss])\n",
    "        \n",
    "        # Log validation losses to TensorBoard\n",
    "        with tf.summary.create_file_writer(log_dir).as_default():\n",
    "            tf.summary.scalar('Generator Loss (Train)', avg_gen_loss, step=epoch)\n",
    "            tf.summary.scalar('Discriminator Loss (Train)', avg_disc_loss, step=epoch)\n",
    "            tf.summary.scalar('Generator Loss (Val)', avg_val_gen_loss, step=epoch)\n",
    "            tf.summary.scalar('Discriminator Loss (Val)', avg_val_disc_loss, step=epoch)\n",
    "            tf.summary.scalar('Total Validation Loss', avg_val_loss, step=epoch)\n",
    "        \n",
    "        # Print metrics\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}\")\n",
    "        tqdm.write(f\"Generator Loss: {avg_gen_loss:.4f}, Discriminator Loss: {avg_disc_loss:.4f}\")\n",
    "        tqdm.write(f\"Validation Generator Loss: {avg_val_gen_loss:.4f}, Validation Discriminator Loss: {avg_val_disc_loss:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            wait = 0\n",
    "            # Save the best models\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            tqdm.write(\"Validation loss improved. Checkpoint saved.\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            tqdm.write(f\"No improvement in validation loss for {wait} epochs.\")\n",
    "            if wait >= patience:\n",
    "                tqdm.write(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Every 10 epochs, perform evaluation\n",
    "        if epoch % 10 == 0:\n",
    "            # Generate images\n",
    "            generate_and_save_images(generator, epoch, test_grayscale)\n",
    "            \n",
    "            # Generate output\n",
    "            generated_images = generator(test_grayscale, training=False)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "            tqdm.write(f\"SSIM Score: {ssim_score:.4f}\")\n",
    "            tqdm.write(f\"PSNR Score: {psnr_score:.4f}\")\n",
    "            \n",
    "            # Log evaluation metrics to separate CSV\n",
    "            with open(eval_csv_file, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([epoch, ssim_score, psnr_score])\n",
    "            \n",
    "            # Log evaluation metrics to TensorBoard\n",
    "            with tf.summary.create_file_writer(log_dir).as_default():\n",
    "                tf.summary.scalar('SSIM Score', ssim_score, step=epoch)\n",
    "                tf.summary.scalar('PSNR Score', psnr_score, step=epoch)\n",
    "    \n",
    "    # 9. Plotting Function\n",
    "def plot_metrics(train_csv, eval_csv, output_dir='output'):\n",
    "    \"\"\"\n",
    "    Plots training and evaluation metrics from CSV files.\n",
    "    \n",
    "    Args:\n",
    "        train_csv (str): Path to the training metrics CSV file.\n",
    "        eval_csv (str): Path to the evaluation metrics CSV file.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load training metrics\n",
    "    train_epochs = []\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    with open(train_csv, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            train_epochs.append(int(row['Epoch']))\n",
    "            gen_losses.append(float(row['Generator Loss']))\n",
    "            disc_losses.append(float(row['Discriminator Loss']))\n",
    "    \n",
    "    # Load evaluation metrics\n",
    "    eval_epochs = []\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    with open(eval_csv, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            eval_epochs.append(int(row['Epoch']))\n",
    "            ssim_scores.append(float(row['SSIM Score']))\n",
    "            psnr_scores.append(float(row['PSNR Score']))\n",
    "    \n",
    "    # Plot Generator and Discriminator Losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_epochs, gen_losses, label='Generator Loss')\n",
    "    plt.plot(train_epochs, disc_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'training_losses.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot SSIM and PSNR Scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_epochs, ssim_scores, label='SSIM Score')\n",
    "    plt.plot(eval_epochs, psnr_scores, label='PSNR Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'evaluation_metrics.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Plots saved in '{output_dir}' directory.\")\n",
    "\n",
    "# 10. Final Evaluation and Plotting\n",
    "def finalize_training(checkpoint_dir='./checkpoints', train_csv='output/training_metrics.csv', eval_csv='output/evaluation_metrics.csv'):\n",
    "    \"\"\"\n",
    "    Restores the best model, performs final evaluation, and plots metrics.\n",
    "    \"\"\"\n",
    "    # Restore the best checkpoint\n",
    "    latest_ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if latest_ckpt:\n",
    "        print(f\"Restoring from checkpoint: {latest_ckpt}\")\n",
    "        checkpoint.restore(latest_ckpt)\n",
    "    else:\n",
    "        print(\"No checkpoint found. Proceeding without restoring.\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    _, _, test_dataset = load_and_preprocess_data()\n",
    "    test_grayscale, test_color = next(iter(test_dataset))\n",
    "    \n",
    "    # Generate images\n",
    "    generated_images = generator(test_grayscale, training=False)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "    print(f\"Final SSIM Score: {ssim_score:.4f}\")\n",
    "    print(f\"Final PSNR Score: {psnr_score:.4f}\")\n",
    "    \n",
    "    # Append final evaluation metrics to CSV\n",
    "    with open(eval_csv, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Final Evaluation', ssim_score, psnr_score])\n",
    "    \n",
    "    # Save the final models\n",
    "    generator.save('output/final_generator.h5')\n",
    "    discriminator.save('output/final_discriminator.h5')\n",
    "    print(\"Final models saved.\")\n",
    "    \n",
    "    # Plot metrics\n",
    "    plot_metrics(train_csv, eval_csv, output_dir='output')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # After training completes, plot the metrics\n",
    "    plot_metrics(\n",
    "        train_csv='output/training_metrics.csv',\n",
    "        eval_csv='output/evaluation_metrics.csv',\n",
    "        output_dir='output'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_38      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ input_layer_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_165[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ re_lu_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_166[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ re_lu_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_167[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ re_lu_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_168[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ re_lu_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_169[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_170[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_171 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_171[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ re_lu_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_35 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_43      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ re_lu_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_172 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_173[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ concatenate_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv2d_174[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_36 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_44      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ re_lu_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_175 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_175[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_176 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_176[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_177 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2d_177[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_37 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_45      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ re_lu_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_178[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_179 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_179[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_180 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ concatenate_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_180[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_38 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_46      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ re_lu_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_181 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_181[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_182 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_182[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_183 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_183[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_39 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_38      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_165 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m3,136\u001b[0m │ input_layer_38[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_76 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_165[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_166 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ re_lu_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_166[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_77 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_167 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ re_lu_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_167[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_78 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_168 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,097,664\u001b[0m │ re_lu_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_168[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_79 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_169 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ re_lu_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_169[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_80 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_170 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_170[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_81 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_171 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_171[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ re_lu_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_35 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,194,816\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_82 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_43      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ re_lu_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_172 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,719,104\u001b[0m │ concatenate_43[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_83 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_173 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_173[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_174 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,800\u001b[0m │ concatenate_43[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_16 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │ conv2d_174[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_36 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m2,097,408\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_84 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_44      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m)              │            │ re_lu_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_175 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_44[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_175[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_85 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_176 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_176[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_177 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_44[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_17 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2d_177[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_37 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m524,416\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_86 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_45      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ re_lu_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_178 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m295,040\u001b[0m │ concatenate_45[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_178[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_87 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_179 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_179[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_180 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m32,896\u001b[0m │ concatenate_45[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_18 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_180[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_38 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │    \u001b[38;5;34m131,136\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_88 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_46      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ re_lu_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ re_lu_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_181 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m73,792\u001b[0m │ concatenate_46[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_181[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_89 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_182 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_182[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_183 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m8,256\u001b[0m │ concatenate_46[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_19 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_183[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_39 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │      \u001b[38;5;34m3,075\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,742,595</span> (109.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,742,595\u001b[0m (109.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,731,971</span> (109.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,731,971\u001b[0m (109.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,624</span> (41.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,624\u001b[0m (41.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data:   0%|          | 1/10000 [00:00<05:13, 31.88it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/var/folders/61/x8wy5qqd0rx0wn1t_91hms500000gn/T/ipykernel_4331/951804591.py\", line 53, in preprocess_and_update  *\n        img = preprocess_image(img)\n\n    TypeError: tf__preprocess_image() missing 1 required positional argument: 'target'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 592\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Run the main function and finalize training\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 592\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# After training completes, perform final evaluation and plotting\u001b[39;00m\n\u001b[1;32m    594\u001b[0m     finalize_training(\n\u001b[1;32m    595\u001b[0m         checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    596\u001b[0m         train_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/training_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    597\u001b[0m         eval_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/evaluation_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    598\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    599\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[25], line 417\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    414\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSIM Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR Score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Build models\u001b[39;00m\n\u001b[1;32m    420\u001b[0m generator \u001b[38;5;241m=\u001b[39m build_generator()\n",
      "Cell \u001b[0;32mIn[25], line 56\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(batch_size, num_samples)\u001b[0m\n\u001b[1;32m     53\u001b[0m     img \u001b[38;5;241m=\u001b[39m preprocess_image(img)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img, img  \u001b[38;5;66;03m# Input and target are initially the same\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_and_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m img_color, img_color2: (rgb_to_grayscale(img_color), img_color2),\n\u001b[1;32m     58\u001b[0m                                   num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     59\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(augment, num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2299\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/61/x8wy5qqd0rx0wn1t_91hms500000gn/T/__autograph_generated_filefup8tg7k.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_and_update\u001b[0;34m(img, label)\u001b[0m\n\u001b[1;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(pbar)\u001b[38;5;241m.\u001b[39mupdate, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_metal/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/var/folders/61/x8wy5qqd0rx0wn1t_91hms500000gn/T/ipykernel_4331/951804591.py\", line 53, in preprocess_and_update  *\n        img = preprocess_image(img)\n\n    TypeError: tf__preprocess_image() missing 1 required positional argument: 'target'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "def preprocess_image(image, target):\n",
    "    image = tf.image.resize(image, [256, 256])  # Ensure the image is resized to 256x256\n",
    "    target = tf.image.resize(target, [256, 256])  # Ensure the target is resized to 256x256\n",
    "\n",
    "    image = (image / 127.5) - 1  # Normalize the image to [-1, 1] range\n",
    "    target = (target / 127.5) - 1  # Normalize the target to [-1, 1] range\n",
    "\n",
    "    return image, target\n",
    "\n",
    "def rgb_to_grayscale(image):\n",
    "    \"\"\"Converts RGB image to grayscale.\"\"\"\n",
    "    return tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "def augment(image, label):\n",
    "    \"\"\"Applies random augmentations to images.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label\n",
    "\n",
    "def load_and_preprocess_data(batch_size=32, num_samples=10000):\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 dataset, applies preprocessing and augmentation,\n",
    "    and prepares training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    # Load CIFAR-10 dataset\n",
    "    dataset, info = tfds.load('cifar10', with_info=True, as_supervised=True)\n",
    "    train_dataset = dataset['train'].take(num_samples)\n",
    "\n",
    "    # Define split sizes\n",
    "    val_size = int(0.1 * num_samples)  # 10% for validation\n",
    "    test_size = 32  # Fixed test set size\n",
    "\n",
    "    # Preprocess and augment the data\n",
    "    with tqdm(total=num_samples, desc=\"Preprocessing data\") as pbar:\n",
    "        def preprocess_and_update(img, label):\n",
    "            pbar.update(1)\n",
    "            img = preprocess_image(img)\n",
    "            return img, img  # Input and target are initially the same\n",
    "\n",
    "        train_dataset = train_dataset.map(preprocess_and_update, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(lambda img_color, img_color2: (rgb_to_grayscale(img_color), img_color2),\n",
    "                                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.cache()\n",
    "        train_dataset = train_dataset.shuffle(1000)\n",
    "        train_dataset = train_dataset.batch(batch_size)\n",
    "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Split into training and validation\n",
    "    val_dataset = train_dataset.take(val_size // batch_size)\n",
    "    train_dataset = train_dataset.skip(val_size // batch_size)\n",
    "\n",
    "    # Create a fixed test set\n",
    "    test_dataset = dataset['test'].take(test_size).map(lambda img, lbl: preprocess_image(img))\n",
    "    test_dataset = test_dataset.map(lambda img: (rgb_to_grayscale(img), img))\n",
    "    test_dataset = test_dataset.batch(test_size)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# 2. Residual Block for Generator\n",
    "# Define the residual block with an option to control output channels\n",
    "# Define the residual block with an option to control output channels\n",
    "def residual_block(x, filters):\n",
    "    skip = x  # Save the input tensor for the skip connection\n",
    "\n",
    "    # First convolutional layer\n",
    "    x = keras.layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    x = keras.layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # If skip connection has a different number of channels, project it to match\n",
    "    if skip.shape[-1] != filters:\n",
    "        skip = keras.layers.Conv2D(filters, (1, 1), padding='same')(skip)\n",
    "    \n",
    "    # Skip connection: add input and output\n",
    "    x = keras.layers.Add()([x, skip])\n",
    "    return x\n",
    "\n",
    "\n",
    "# Generator model (U-Net style with residual blocks)\n",
    "def build_generator():\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    # Encoder\n",
    "    e1 = keras.layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)    # 128x128x64\n",
    "    e1 = keras.layers.ReLU()(e1)\n",
    "    \n",
    "    e2 = keras.layers.Conv2D(128, (4, 4), strides=2, padding='same')(e1)       # 64x64x128\n",
    "    e2 = keras.layers.BatchNormalization()(e2)\n",
    "    e2 = keras.layers.ReLU()(e2)\n",
    "    \n",
    "    e3 = keras.layers.Conv2D(256, (4, 4), strides=2, padding='same')(e2)       # 32x32x256\n",
    "    e3 = keras.layers.BatchNormalization()(e3)\n",
    "    e3 = keras.layers.ReLU()(e3)\n",
    "    \n",
    "    e4 = keras.layers.Conv2D(512, (4, 4), strides=2, padding='same')(e3)       # 16x16x512\n",
    "    e4 = keras.layers.BatchNormalization()(e4)\n",
    "    e4 = keras.layers.ReLU()(e4)\n",
    "    \n",
    "    e5 = keras.layers.Conv2D(512, (4, 4), strides=2, padding='same')(e4)       # 8x8x512\n",
    "    e5 = keras.layers.BatchNormalization()(e5)\n",
    "    e5 = keras.layers.ReLU()(e5)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b = residual_block(e5, 512)                                                # 8x8x512\n",
    "    \n",
    "    # Decoder\n",
    "    d1 = keras.layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same')(b)  # 16x16x512\n",
    "    d1 = keras.layers.BatchNormalization()(d1)\n",
    "    d1 = keras.layers.ReLU()(d1)\n",
    "    d1 = keras.layers.Concatenate()([d1, e4])                                  # 16x16x1024\n",
    "    \n",
    "    d1 = residual_block(d1, 512)                                               # Ensure it has 512 channels\n",
    "    \n",
    "    d2 = keras.layers.Conv2DTranspose(256, (4, 4), strides=2, padding='same')(d1)  # 32x32x256\n",
    "    d2 = keras.layers.BatchNormalization()(d2)\n",
    "    d2 = keras.layers.ReLU()(d2)\n",
    "    d2 = keras.layers.Concatenate()([d2, e3])                                  # 32x32x512\n",
    "    \n",
    "    d2 = residual_block(d2, 256)                                               # Ensure it has 256 channels\n",
    "    \n",
    "    d3 = keras.layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same')(d2)  # 64x64x128\n",
    "    d3 = keras.layers.BatchNormalization()(d3)\n",
    "    d3 = keras.layers.ReLU()(d3)\n",
    "    d3 = keras.layers.Concatenate()([d3, e2])                                  # 64x64x256\n",
    "    \n",
    "    d3 = residual_block(d3, 128)                                               # Ensure it has 128 channels\n",
    "    \n",
    "    d4 = keras.layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same')(d3)  # 128x128x64\n",
    "    d4 = keras.layers.BatchNormalization()(d4)\n",
    "    d4 = keras.layers.ReLU()(d4)\n",
    "    d4 = keras.layers.Concatenate()([d4, e1])                                  # 128x128x128\n",
    "    \n",
    "    d4 = residual_block(d4, 64)                                                # Ensure it has 64 channels\n",
    "    \n",
    "    # Final layer\n",
    "    outputs = keras.layers.Conv2DTranspose(3, (4, 4), strides=2, padding='same', activation='tanh')(d4)  # 256x256x3\n",
    "    \n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "# Call the generator function\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "# 4. Spectral Normalization Wrapper\n",
    "def SpectralNormalization(layer):\n",
    "    \"\"\"Applies spectral normalization to a given layer.\"\"\"\n",
    "    return keras.layers.LayerNormalization()(layer)\n",
    "\n",
    "# 5. Build Discriminator with Spectral Normalization\n",
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Builds the discriminator model to classify real and generated images.\n",
    "    Incorporates spectral normalization for stability.\n",
    "    \"\"\"\n",
    "    input_img = keras.Input(shape=(32, 32, 1))\n",
    "    target_img = keras.Input(shape=(32, 32, 3))\n",
    "    x = keras.layers.Concatenate()([input_img, target_img])  # 32x32x4\n",
    "    \n",
    "    # Convolutional Layers with Spectral Normalization\n",
    "    x = keras.layers.Conv2D(64, 4, strides=2, padding='same',\n",
    "                            kernel_initializer=keras.initializers.RandomNormal(0, 0.02),\n",
    "                            kernel_regularizer=keras.regularizers.l2(0.0001))(x)  # 16x16x64\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(128, 4, strides=2, padding='same',\n",
    "                            kernel_initializer=keras.initializers.RandomNormal(0, 0.02),\n",
    "                            kernel_regularizer=keras.regularizers.l2(0.0001))(x)  # 8x8x128\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(256, 4, strides=2, padding='same',\n",
    "                            kernel_initializer=keras.initializers.RandomNormal(0, 0.02),\n",
    "                            kernel_regularizer=keras.regularizers.l2(0.0001))(x)  # 4x4x256\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Final Layer\n",
    "    x = keras.layers.Conv2D(1, 4, strides=1, padding='same',\n",
    "                            kernel_initializer=keras.initializers.RandomNormal(0, 0.02),\n",
    "                            kernel_regularizer=keras.regularizers.l2(0.0001))(x)    # 4x4x1\n",
    "    \n",
    "    return keras.Model([input_img, target_img], x, name=\"Discriminator\")\n",
    "\n",
    "# 6. Loss Functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target, l1_weight=10):\n",
    "    \"\"\"\n",
    "    Calculates generator loss which is a combination of GAN loss and L1 loss.\n",
    "    \"\"\"\n",
    "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_loss = gan_loss + (l1_weight * l1_loss)\n",
    "    return total_loss, gan_loss, l1_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    \"\"\"\n",
    "    Calculates discriminator loss.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_loss = real_loss + generated_loss\n",
    "    return total_loss\n",
    "\n",
    "# 7. Training Step\n",
    "@tf.function\n",
    "def train_step(input_image, target, generator, discriminator, generator_optimizer, discriminator_optimizer, l1_weight=10):\n",
    "    \"\"\"\n",
    "    Performs one training step for both generator and discriminator.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate output\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        \n",
    "        # Discriminator output\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "        \n",
    "        # Calculate losses\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
    "            disc_generated_output, gen_output, target, l1_weight=l1_weight\n",
    "        )\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_total_loss, disc_loss\n",
    "\n",
    "# 8. Image Generation and Saving\n",
    "def generate_and_save_images(model, epoch, test_input, save_dir='output', max_images=16):\n",
    "    \"\"\"\n",
    "    Generates images using the generator and saves them to disk.\n",
    "    \"\"\"\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    num_images = min(predictions.shape[0], max_images)\n",
    "    grid_size = math.ceil(math.sqrt(num_images))\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(grid_size, grid_size, i+1)\n",
    "        img = (predictions[i] * 0.5) + 0.5  # Rescale to [0, 1]\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 9. Evaluation Metrics\n",
    "def calculate_metrics(real_images, generated_images, win_size=7):\n",
    "    \"\"\"\n",
    "    Calculates average SSIM and PSNR between real and generated images.\n",
    "    \n",
    "    Args:\n",
    "        real_images (tf.Tensor): Batch of real images.\n",
    "        generated_images (tf.Tensor): Batch of generated images.\n",
    "        win_size (int): Window size for SSIM. Must be odd and <= min(image dimensions).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average SSIM, average PSNR)\n",
    "    \"\"\"\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    \n",
    "    for real, generated in tqdm(zip(real_images, generated_images), desc=\"Calculating metrics\", total=len(real_images)):\n",
    "        # Rescale images from [-1, 1] to [0, 255]\n",
    "        real = ((real * 0.5) + 0.5) * 255\n",
    "        generated = ((generated * 0.5) + 0.5) * 255\n",
    "        \n",
    "        # Convert tensors to NumPy arrays\n",
    "        real = real.numpy().astype(np.uint8)\n",
    "        generated = generated.numpy().astype(np.uint8)\n",
    "        \n",
    "        # Ensure images have 3 channels\n",
    "        if real.ndim == 3 and real.shape[-1] == 1:\n",
    "            real = np.squeeze(real, axis=-1)\n",
    "        if generated.ndim ==3 and generated.shape[-1] ==1:\n",
    "            generated = np.squeeze(generated, axis=-1)\n",
    "        \n",
    "        # Calculate SSIM with updated parameters\n",
    "        try:\n",
    "            ssim_val = ssim(\n",
    "                real, \n",
    "                generated, \n",
    "                win_size=win_size, \n",
    "                multichannel=True\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"SSIM calculation error: {e}\")\n",
    "            ssim_val = 0  # Assign a default value or handle as needed\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_val = psnr(\n",
    "            real, \n",
    "            generated, \n",
    "            data_range=255\n",
    "        )\n",
    "        \n",
    "        ssim_scores.append(ssim_val)\n",
    "        psnr_scores.append(psnr_val)\n",
    "    \n",
    "    return np.mean(ssim_scores), np.mean(psnr_scores)\n",
    "\n",
    "# 10. Plotting Function\n",
    "def plot_metrics(train_csv, eval_csv, output_dir='output'):\n",
    "    \"\"\"\n",
    "    Plots training and evaluation metrics from CSV files.\n",
    "    \n",
    "    Args:\n",
    "        train_csv (str): Path to the training metrics CSV file.\n",
    "        eval_csv (str): Path to the evaluation metrics CSV file.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load training metrics\n",
    "    train_epochs = []\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    with open(train_csv, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            train_epochs.append(int(row['Epoch']))\n",
    "            gen_losses.append(float(row['Generator Loss']))\n",
    "            disc_losses.append(float(row['Discriminator Loss']))\n",
    "    \n",
    "    # Load evaluation metrics\n",
    "    eval_epochs = []\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    with open(eval_csv, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            eval_epochs.append(int(row['Epoch']))\n",
    "            ssim_scores.append(float(row['SSIM Score']))\n",
    "            psnr_scores.append(float(row['PSNR Score']))\n",
    "    \n",
    "    # Plot Generator and Discriminator Losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_epochs, gen_losses, label='Generator Loss')\n",
    "    plt.plot(train_epochs, disc_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'training_losses.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot SSIM and PSNR Scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(eval_epochs, ssim_scores, label='SSIM Score')\n",
    "    plt.plot(eval_epochs, psnr_scores, label='PSNR Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'evaluation_metrics.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Plots saved in '{output_dir}' directory.\")\n",
    "\n",
    "# 11. Main Execution with Enhancements\n",
    "def main():\n",
    "    # Set random seed for reproducibility (optional)\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create a directory to save outputs if not exists\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    \n",
    "    # Initialize CSV files\n",
    "    train_csv_file = os.path.join('output', 'training_metrics.csv')\n",
    "    eval_csv_file = os.path.join('output', 'evaluation_metrics.csv')\n",
    "    \n",
    "    with open(train_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'Generator Loss', 'Discriminator Loss'])\n",
    "    \n",
    "    with open(eval_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write headers\n",
    "        writer.writerow(['Epoch', 'SSIM Score', 'PSNR Score'])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    train_dataset, val_dataset, test_dataset = load_and_preprocess_data()\n",
    "    \n",
    "    # Build models\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    # Define optimizers with lower learning rates\n",
    "    generator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "    \n",
    "    # Define number of epochs and patience for early stopping\n",
    "    epochs = 100\n",
    "    patience = 15  # For early stopping\n",
    "    \n",
    "    # Setup TensorBoard\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Setup Model Checkpointing\n",
    "    checkpoint_dir = './checkpoints'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        generator_optimizer=generator_optimizer,\n",
    "        discriminator_optimizer=discriminator_optimizer\n",
    "    )\n",
    "    \n",
    "    # Select a fixed test set for consistent evaluation\n",
    "    test_grayscale, test_color = next(iter(test_dataset))\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in tqdm(range(1, epochs + 1), desc=\"Training epochs\"):\n",
    "        gen_losses = []\n",
    "        disc_losses = []\n",
    "        \n",
    "        # Training\n",
    "        for input_image, target in tqdm(train_dataset, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "            gen_total_loss, disc_loss = train_step(\n",
    "                input_image, target, generator, discriminator, \n",
    "                generator_optimizer, discriminator_optimizer, \n",
    "                l1_weight=10  # Adjusted L1 weight\n",
    "            )\n",
    "            gen_losses.append(gen_total_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_gen_loss = tf.reduce_mean(gen_losses).numpy()\n",
    "        avg_disc_loss = tf.reduce_mean(disc_losses).numpy()\n",
    "        \n",
    "        # Validation\n",
    "        val_gen_losses = []\n",
    "        val_disc_losses = []\n",
    "        for val_input, val_target in val_dataset:\n",
    "            # Generate output\n",
    "            gen_output = generator(val_input, training=False)\n",
    "            \n",
    "            # Discriminator output\n",
    "            disc_real_output = discriminator([val_input, val_target], training=False)\n",
    "            disc_generated_output = discriminator([val_input, gen_output], training=False)\n",
    "            \n",
    "            # Calculate losses\n",
    "            val_gen_total_loss, val_gen_gan_loss, val_gen_l1_loss = generator_loss(\n",
    "                disc_generated_output, gen_output, val_target, l1_weight=10\n",
    "            )\n",
    "            val_disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            val_gen_losses.append(val_gen_total_loss)\n",
    "            val_disc_losses.append(val_disc_loss)\n",
    "        \n",
    "        # Calculate average validation losses\n",
    "        avg_val_gen_loss = tf.reduce_mean(val_gen_losses).numpy()\n",
    "        avg_val_disc_loss = tf.reduce_mean(val_disc_losses).numpy()\n",
    "        avg_val_loss = avg_val_gen_loss + avg_val_disc_loss\n",
    "        \n",
    "        # Log training losses to CSV\n",
    "        with open(train_csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch, avg_gen_loss, avg_disc_loss])\n",
    "        \n",
    "        # Log validation losses to TensorBoard\n",
    "        with tf.summary.create_file_writer(log_dir).as_default():\n",
    "            tf.summary.scalar('Generator Loss (Train)', avg_gen_loss, step=epoch)\n",
    "            tf.summary.scalar('Discriminator Loss (Train)', avg_disc_loss, step=epoch)\n",
    "            tf.summary.scalar('Generator Loss (Val)', avg_val_gen_loss, step=epoch)\n",
    "            tf.summary.scalar('Discriminator Loss (Val)', avg_val_disc_loss, step=epoch)\n",
    "            tf.summary.scalar('Total Validation Loss', avg_val_loss, step=epoch)\n",
    "        \n",
    "        # Print metrics\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}\")\n",
    "        tqdm.write(f\"Generator Loss: {avg_gen_loss:.4f}, Discriminator Loss: {avg_disc_loss:.4f}\")\n",
    "        tqdm.write(f\"Validation Generator Loss: {avg_val_gen_loss:.4f}, Validation Discriminator Loss: {avg_val_disc_loss:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            wait = 0\n",
    "            # Save the best models\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            tqdm.write(\"Validation loss improved. Checkpoint saved.\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            tqdm.write(f\"No improvement in validation loss for {wait} epochs.\")\n",
    "            if wait >= patience:\n",
    "                tqdm.write(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Every 10 epochs, perform evaluation\n",
    "        if epoch % 10 == 0:\n",
    "            # Generate images\n",
    "            generate_and_save_images(generator, epoch, test_grayscale)\n",
    "            \n",
    "            # Generate output\n",
    "            generated_images = generator(test_grayscale, training=False)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "            tqdm.write(f\"SSIM Score: {ssim_score:.4f}\")\n",
    "            tqdm.write(f\"PSNR Score: {psnr_score:.4f}\")\n",
    "            \n",
    "            # Log evaluation metrics to separate CSV\n",
    "            with open(eval_csv_file, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([epoch, ssim_score, psnr_score])\n",
    "            \n",
    "            # Log evaluation metrics to TensorBoard\n",
    "            with tf.summary.create_file_writer(log_dir).as_default():\n",
    "                tf.summary.scalar('SSIM Score', ssim_score, step=epoch)\n",
    "                tf.summary.scalar('PSNR Score', psnr_score, step=epoch)\n",
    "    \n",
    "# 12. Final Evaluation and Plotting\n",
    "def finalize_training(checkpoint_dir='./checkpoints', train_csv='output/training_metrics.csv', eval_csv='output/evaluation_metrics.csv'):\n",
    "    \"\"\"\n",
    "    Restores the best model, performs final evaluation, and plots metrics.\n",
    "    \"\"\"\n",
    "    # Restore the best checkpoint\n",
    "    latest_ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if latest_ckpt:\n",
    "        print(f\"Restoring from checkpoint: {latest_ckpt}\")\n",
    "        checkpoint.restore(latest_ckpt)\n",
    "    else:\n",
    "        print(\"No checkpoint found. Proceeding without restoring.\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    _, _, test_dataset = load_and_preprocess_data()\n",
    "    test_grayscale, test_color = next(iter(test_dataset))\n",
    "    \n",
    "    # Generate images\n",
    "    generated_images = generator(test_grayscale, training=False)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ssim_score, psnr_score = calculate_metrics(test_color, generated_images)\n",
    "    print(f\"Final SSIM Score: {ssim_score:.4f}\")\n",
    "    print(f\"Final PSNR Score: {psnr_score:.4f}\")\n",
    "    \n",
    "    # Append final evaluation metrics to CSV\n",
    "    with open(eval_csv, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Final Evaluation', ssim_score, psnr_score])\n",
    "    \n",
    "    # Save the final models\n",
    "    generator.save('output/final_generator.h5')\n",
    "    discriminator.save('output/final_discriminator.h5')\n",
    "    print(\"Final models saved.\")\n",
    "    \n",
    "    # Plot metrics\n",
    "    plot_metrics(train_csv, eval_csv, output_dir='output')\n",
    "\n",
    "# Run the main function and finalize training\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # After training completes, perform final evaluation and plotting\n",
    "    finalize_training(\n",
    "        checkpoint_dir='./checkpoints',\n",
    "        train_csv='output/training_metrics.csv',\n",
    "        eval_csv='output/evaluation_metrics.csv',\n",
    "        output_dir='output'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
